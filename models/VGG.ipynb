{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b2a7c3e-c203-4734-9f89-1df72e269ec8",
   "metadata": {},
   "source": [
    "## VGG Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "caed9acf-3fa2-4298-8439-44f0c1d0cc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f72cc2f8-de98-4be3-8828-4afd2e4d5136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n"
     ]
    }
   ],
   "source": [
    "USE_GPU = True\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print('using device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b4fc9d-a9e2-45c8-9dc5-99ba3e13c165",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3dd6aabe-681f-447a-8b9e-b3993bc93449",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VehicleDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, path):\n",
    "        data = np.load(path)\n",
    "        self.images = data[\"images\"]\n",
    "        self.labels = data[\"labels\"]\n",
    "        print(\"Images shape:\", self.images.shape)\n",
    "        print(\"Labels shape:\", self.labels.shape)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        image = torch.tensor(image, dtype=torch.float32).permute(2, 0, 1) / 255.0\n",
    "        label = torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "        mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "        std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "        image = (image - mean) / std\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d6c6ca5b-c047-421b-b0c0-a6555f88b332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images shape: (8144, 64, 64, 3)\n",
      "Labels shape: (8144, 1)\n"
     ]
    }
   ],
   "source": [
    "dataset = VehicleDataset('../dataset/stanford_cars_dataset.npz')\n",
    "\n",
    "batch_size = 32\n",
    "train_size = int(0.7 * len(dataset))\n",
    "val_size = int(0.2 * len(dataset))\n",
    "test_size = int(len(dataset) - train_size - val_size)\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a24f84c-ad48-4270-b0a5-3d9a37ba56d5",
   "metadata": {},
   "source": [
    "### VGG Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "03c64be2-5004-40eb-8cd6-d3b2f3078bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, bias=False)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bac973ea-b151-4502-ab75-0a3dec6a8987",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG11(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGG11, self).__init__()\n",
    "        self.layer1 = BasicBlock(3, 64)\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.layer2 = BasicBlock(64, 128)\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.layer3 = BasicBlock(128, 256)\n",
    "        self.layer4 = BasicBlock(256, 256)\n",
    "        self.maxpool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.layer5 = BasicBlock(256, 512)\n",
    "        self.layer6 = BasicBlock(512, 512)\n",
    "        self.maxpool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.layer7 = BasicBlock(512, 512)\n",
    "        self.layer8 = BasicBlock(512, 512)\n",
    "        self.maxpool5 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512 * 2 * 2, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.7),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.7),\n",
    "            nn.Linear(4096, 196)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.maxpool3(x)\n",
    "        x = self.layer5(x)\n",
    "        x = self.layer6(x)\n",
    "        x = self.maxpool4(x)\n",
    "        x = self.layer7(x)\n",
    "        x = self.layer8(x)\n",
    "        x = self.maxpool5(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af90e79d-5f40-4fe7-ba45-325d04f6f5fa",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fea74392-4514-4d84-bfc6-c97526b9e260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = VGG11().to(device)\n",
    "def train_model(model):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    num_epochs = 5\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "    \n",
    "        for images, labels in train_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels[:,0].to(device) - 1\n",
    "\n",
    "            # Forward\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Metrics\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / total\n",
    "        epoch_acc = correct / total\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} - Loss: {epoch_loss:.4f} - Accuracy: {epoch_acc:.4f}\")\n",
    "    \n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images = images.to(device)\n",
    "                labels = labels[:,0].to(device) - 1\n",
    "            \n",
    "                outputs = model(images)\n",
    "                preds = torch.argmax(outputs, dim=1)\n",
    "                correct += (preds == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "        val_acc = correct / total\n",
    "        print(f'Validation Acc: {val_acc:.4f}')\n",
    "        # return val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "79a9816e-a2a2-4c8b-a3f6-8328947bc836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 - Loss: 5.3065 - Accuracy: 0.0079\n",
      "Validation Acc: 0.0025\n",
      "Epoch 2/5 - Loss: 5.2797 - Accuracy: 0.0098\n",
      "Validation Acc: 0.0025\n",
      "Epoch 3/5 - Loss: 5.2776 - Accuracy: 0.0098\n",
      "Validation Acc: 0.0025\n",
      "Epoch 4/5 - Loss: 5.2767 - Accuracy: 0.0098\n",
      "Validation Acc: 0.0025\n",
      "Epoch 5/5 - Loss: 5.2750 - Accuracy: 0.0098\n",
      "Validation Acc: 0.0025\n"
     ]
    }
   ],
   "source": [
    "model = VGG11().to(device)\n",
    "train_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52b1566-1bfc-4582-8144-dde6825d350d",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d1fed680-c356-4df1-9a07-0658bfbbe5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_loader, device):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels[:,0].to(device) - 1 \n",
    "            \n",
    "            outputs = model(images)\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "            all_preds.append(preds.cpu())\n",
    "            all_labels.append(labels.cpu())\n",
    "\n",
    "    accuracy = correct / total\n",
    "    print(f'Test Accuracy: {accuracy:.4f}')\n",
    "\n",
    "    # Concatenate all predictions and labels if needed for further analysis\n",
    "    all_preds = torch.cat(all_preds)\n",
    "    all_labels = torch.cat(all_labels)\n",
    "    \n",
    "    return accuracy, all_preds, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1360631b-7a2f-4c08-b5b7-513e1a8caf80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.0098\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.00980392156862745,\n",
       " tensor([118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118]),\n",
       " tensor([ 28, 172,  14,  69,  88, 142,  47,  29,   7,   0, 123,  77, 193, 126,\n",
       "         179,  32, 114, 125, 122,  15,  46, 185,  34,  46,  17,  44, 116,  94,\n",
       "           5, 122, 169,  45, 186,  95,  56, 189,  65, 146,  72, 157, 117,  69,\n",
       "         101,   7,  95,  70,  77, 125, 123,  80, 171,  91,  42,  36, 190,  85,\n",
       "         109,  81, 159, 178, 103, 105, 195, 132, 117,   5, 111, 118, 103, 149,\n",
       "         113, 145,  61,   6, 140,  19, 146,  36,  22, 165, 192,   9,  39,   1,\n",
       "          45, 138, 186,  64,  78, 189, 139,  33, 139,  33, 134,  20, 177, 192,\n",
       "          47,  51,  35, 133, 119, 124, 179, 117, 142,  93, 123, 120,  73,  40,\n",
       "          59, 153, 191,   8, 147,  59,  99,  45, 101, 133,  67,  77,  55,  73,\n",
       "         152, 126, 117, 192,  10, 167,  66, 176,  58, 115,   5, 106, 108, 179,\n",
       "           8,  94, 116,  21,  78, 105,  96, 124, 167,  87, 151, 166, 156,  47,\n",
       "          18,  89,  69,  72, 143,  16,  45,  92, 190, 145, 165, 187,  93,  92,\n",
       "         121, 133, 131, 168, 112, 103,  64, 122, 165, 104,  69,  89,  20,  85,\n",
       "         114, 175, 123, 193,  45, 152, 107, 136,  41, 145,  85,  66,  25,  79,\n",
       "         185,  93,  92,  58,  88,  56,  53,   1, 186, 195,  75,  45,  88, 185,\n",
       "          57,  47,   5,  90, 150, 102,  39,   8,   4, 117,  52, 119, 124, 128,\n",
       "         177, 193, 185,  73,  64, 130,  86,  55, 139, 188, 144,  85, 160,   4,\n",
       "          59,  98, 169,  46,  58, 144,  91, 163, 114,   7, 146, 150,  96,   9,\n",
       "          96, 152, 165, 185, 183, 143,  15, 131,  20, 195, 124, 168,  49, 146,\n",
       "          17, 100, 194,   5, 160,  15,  51,  37,  97,   7,  22, 165,   5,  85,\n",
       "         181, 118,  81,  37, 113,  94,  43,  73,  37,  16,  85,  75, 195,  66,\n",
       "         117,  58,  97,  97, 136,  66, 159, 187, 165, 137, 132, 177, 119, 194,\n",
       "          50, 120,  16, 140,  77,  31, 180,  13, 141, 180, 186, 129,  64,   3,\n",
       "         186, 118, 145,  16,  66, 157,   7, 137, 170,  46,  63,  68,  15,  36,\n",
       "          18, 113,   5, 188,  65, 118,   9,  21, 166, 154, 172,  50,  76, 184,\n",
       "          96, 154,  40,  71, 110, 120, 172,  86, 167,  91,  31,  22,  71,   5,\n",
       "         112,  71,  12,  39, 180,   4,  29, 190, 125,  55,  49,  73, 104,  60,\n",
       "          15,  57,  28,   6, 137,  30,  38, 120, 102, 166,  73, 121, 147,  11,\n",
       "         154, 161, 148, 140, 168,  29, 127,  52, 138, 113, 120,  91,  36,  96,\n",
       "          92, 129,   4, 155, 136,  84,  48,  76, 182,  68, 182,  46,  27, 123,\n",
       "          48,   2,  43, 118, 118,  62, 180,  31,   6, 164, 126,   2, 109, 132,\n",
       "          62, 127,  92,  57,  76, 104, 117, 146, 175,  67, 162, 112, 164,  79,\n",
       "          79,  41, 131, 176, 112,  60, 160, 161, 103, 127,  38,   2, 140,  42,\n",
       "         126, 162,   6,  59, 181,  40, 173,  82,  28,   9,  15, 151,  61, 121,\n",
       "         150, 119, 177, 114,  11,  38, 156, 107,   1,  60,  27,  23, 129, 127,\n",
       "         148, 188, 117, 138, 105, 120, 180, 125, 132, 174, 129, 152,  39, 118,\n",
       "          48, 127,  43,  62, 152, 125,   3, 109, 121,  37,  28,  63,  17, 143,\n",
       "          97,  56, 172, 111,  14,   3, 165, 165,  22,  95, 111, 114, 139,  26,\n",
       "         116, 109,  96, 107,  13,  30, 130, 146,  20, 117,  28,  95, 193,  39,\n",
       "          27,  66,  14,  89,   2,  57,  74,  91,   0, 170,  35,  62, 174, 104,\n",
       "         136, 186, 129, 128,   1,  68,  95, 161, 107,  63,  11, 190,  73, 129,\n",
       "         176,  50, 111, 131, 192,  27,  31,  88, 118, 105, 190, 194, 133,  26,\n",
       "          83, 155,   1,  88,  77, 110,   4,  61, 142, 115, 190,  53,  53, 183,\n",
       "         151,   9, 129, 114,  42,  28, 137,  27, 180, 186, 131,  46, 192,  15,\n",
       "         144,  76,  38,  84,  17, 182,   8, 124,  43, 162, 179,  77,  31,  40,\n",
       "          65, 172,  59, 107,  68,  47, 193, 146,  34,   5, 164,   2,  87,  71,\n",
       "         188, 134, 150, 125, 181,  89,  84, 115,  83,  65, 108, 107, 115, 172,\n",
       "          14, 141,  95, 101,  65,  33,  70, 139, 143,  82, 170,  52, 174,  24,\n",
       "          11,  94,  39, 113, 155, 146, 182,  58,  91, 188, 171,  44, 110, 107,\n",
       "           7, 106, 138,  87,  38,   8,  69,  58, 102,  34, 107,  64, 170,  97,\n",
       "         113, 152,  35, 108,  79,  95, 128, 158, 180, 104,  92, 179,  97, 178,\n",
       "          28, 164,  41,  41, 163, 137, 130,  36, 136, 164, 155, 182, 132,  98,\n",
       "         128,  58, 152, 164, 195, 159,  16,  55, 101, 188, 157, 172,  91,  52,\n",
       "         124, 142,  89,  71,  47, 174, 131, 147,  50,  38,  10,  30, 192, 160,\n",
       "           2, 155, 144,  62,  50, 122, 149,  95, 106,  71, 128, 182, 189, 171,\n",
       "         154,  32, 156, 145, 112,  71,  78,  49,  25, 174, 136, 173, 102,  82,\n",
       "          53,  11,  22,   3, 123, 152, 140, 182, 192, 112,  72,  12, 113,  58,\n",
       "          16, 126, 155,  53, 130, 113, 163,  50,  85, 184,  77, 116,  73, 100,\n",
       "         193,  24, 119, 137]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9f39d0b7-88a4-4822-bcfe-feb6738326ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG13(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGG13, self).__init__()\n",
    "        self.layer1 = BasicBlock(3, 64)\n",
    "        self.layer11 = BasicBlock(64, 64)\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.layer2 = BasicBlock(64, 128)\n",
    "        self.layer22 = BasicBlock(128, 128)\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.layer3 = BasicBlock(128, 256)\n",
    "        self.layer4 = BasicBlock(256, 256)\n",
    "        self.maxpool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.layer5 = BasicBlock(256, 512)\n",
    "        self.layer6 = BasicBlock(512, 512)\n",
    "        self.maxpool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.layer7 = BasicBlock(512, 512)\n",
    "        self.layer8 = BasicBlock(512, 512)\n",
    "        self.maxpool5 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512 * 2 * 2, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4096, 196)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer11(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer22(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.maxpool3(x)\n",
    "        x = self.layer5(x)\n",
    "        x = self.layer6(x)\n",
    "        x = self.maxpool4(x)\n",
    "        x = self.layer7(x)\n",
    "        x = self.layer8(x)\n",
    "        x = self.maxpool5(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f3f7ffe0-d75e-4067-99c9-f7bda9bcb47d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 - Loss: 5.2804 - Accuracy: 0.0077\n",
      "Validation Acc: 0.0025\n",
      "Epoch 2/5 - Loss: 5.2772 - Accuracy: 0.0098\n",
      "Validation Acc: 0.0025\n",
      "Epoch 3/5 - Loss: 5.2761 - Accuracy: 0.0098\n",
      "Validation Acc: 0.0025\n",
      "Epoch 4/5 - Loss: 5.2752 - Accuracy: 0.0098\n",
      "Validation Acc: 0.0025\n",
      "Epoch 5/5 - Loss: 5.2744 - Accuracy: 0.0098\n",
      "Validation Acc: 0.0025\n"
     ]
    }
   ],
   "source": [
    "model = VGG13().to(device)\n",
    "train_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5f6079f5-0f41-4f56-9a8e-25204f70a32f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.0098\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.00980392156862745,\n",
       " tensor([118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118]),\n",
       " tensor([ 28, 172,  14,  69,  88, 142,  47,  29,   7,   0, 123,  77, 193, 126,\n",
       "         179,  32, 114, 125, 122,  15,  46, 185,  34,  46,  17,  44, 116,  94,\n",
       "           5, 122, 169,  45, 186,  95,  56, 189,  65, 146,  72, 157, 117,  69,\n",
       "         101,   7,  95,  70,  77, 125, 123,  80, 171,  91,  42,  36, 190,  85,\n",
       "         109,  81, 159, 178, 103, 105, 195, 132, 117,   5, 111, 118, 103, 149,\n",
       "         113, 145,  61,   6, 140,  19, 146,  36,  22, 165, 192,   9,  39,   1,\n",
       "          45, 138, 186,  64,  78, 189, 139,  33, 139,  33, 134,  20, 177, 192,\n",
       "          47,  51,  35, 133, 119, 124, 179, 117, 142,  93, 123, 120,  73,  40,\n",
       "          59, 153, 191,   8, 147,  59,  99,  45, 101, 133,  67,  77,  55,  73,\n",
       "         152, 126, 117, 192,  10, 167,  66, 176,  58, 115,   5, 106, 108, 179,\n",
       "           8,  94, 116,  21,  78, 105,  96, 124, 167,  87, 151, 166, 156,  47,\n",
       "          18,  89,  69,  72, 143,  16,  45,  92, 190, 145, 165, 187,  93,  92,\n",
       "         121, 133, 131, 168, 112, 103,  64, 122, 165, 104,  69,  89,  20,  85,\n",
       "         114, 175, 123, 193,  45, 152, 107, 136,  41, 145,  85,  66,  25,  79,\n",
       "         185,  93,  92,  58,  88,  56,  53,   1, 186, 195,  75,  45,  88, 185,\n",
       "          57,  47,   5,  90, 150, 102,  39,   8,   4, 117,  52, 119, 124, 128,\n",
       "         177, 193, 185,  73,  64, 130,  86,  55, 139, 188, 144,  85, 160,   4,\n",
       "          59,  98, 169,  46,  58, 144,  91, 163, 114,   7, 146, 150,  96,   9,\n",
       "          96, 152, 165, 185, 183, 143,  15, 131,  20, 195, 124, 168,  49, 146,\n",
       "          17, 100, 194,   5, 160,  15,  51,  37,  97,   7,  22, 165,   5,  85,\n",
       "         181, 118,  81,  37, 113,  94,  43,  73,  37,  16,  85,  75, 195,  66,\n",
       "         117,  58,  97,  97, 136,  66, 159, 187, 165, 137, 132, 177, 119, 194,\n",
       "          50, 120,  16, 140,  77,  31, 180,  13, 141, 180, 186, 129,  64,   3,\n",
       "         186, 118, 145,  16,  66, 157,   7, 137, 170,  46,  63,  68,  15,  36,\n",
       "          18, 113,   5, 188,  65, 118,   9,  21, 166, 154, 172,  50,  76, 184,\n",
       "          96, 154,  40,  71, 110, 120, 172,  86, 167,  91,  31,  22,  71,   5,\n",
       "         112,  71,  12,  39, 180,   4,  29, 190, 125,  55,  49,  73, 104,  60,\n",
       "          15,  57,  28,   6, 137,  30,  38, 120, 102, 166,  73, 121, 147,  11,\n",
       "         154, 161, 148, 140, 168,  29, 127,  52, 138, 113, 120,  91,  36,  96,\n",
       "          92, 129,   4, 155, 136,  84,  48,  76, 182,  68, 182,  46,  27, 123,\n",
       "          48,   2,  43, 118, 118,  62, 180,  31,   6, 164, 126,   2, 109, 132,\n",
       "          62, 127,  92,  57,  76, 104, 117, 146, 175,  67, 162, 112, 164,  79,\n",
       "          79,  41, 131, 176, 112,  60, 160, 161, 103, 127,  38,   2, 140,  42,\n",
       "         126, 162,   6,  59, 181,  40, 173,  82,  28,   9,  15, 151,  61, 121,\n",
       "         150, 119, 177, 114,  11,  38, 156, 107,   1,  60,  27,  23, 129, 127,\n",
       "         148, 188, 117, 138, 105, 120, 180, 125, 132, 174, 129, 152,  39, 118,\n",
       "          48, 127,  43,  62, 152, 125,   3, 109, 121,  37,  28,  63,  17, 143,\n",
       "          97,  56, 172, 111,  14,   3, 165, 165,  22,  95, 111, 114, 139,  26,\n",
       "         116, 109,  96, 107,  13,  30, 130, 146,  20, 117,  28,  95, 193,  39,\n",
       "          27,  66,  14,  89,   2,  57,  74,  91,   0, 170,  35,  62, 174, 104,\n",
       "         136, 186, 129, 128,   1,  68,  95, 161, 107,  63,  11, 190,  73, 129,\n",
       "         176,  50, 111, 131, 192,  27,  31,  88, 118, 105, 190, 194, 133,  26,\n",
       "          83, 155,   1,  88,  77, 110,   4,  61, 142, 115, 190,  53,  53, 183,\n",
       "         151,   9, 129, 114,  42,  28, 137,  27, 180, 186, 131,  46, 192,  15,\n",
       "         144,  76,  38,  84,  17, 182,   8, 124,  43, 162, 179,  77,  31,  40,\n",
       "          65, 172,  59, 107,  68,  47, 193, 146,  34,   5, 164,   2,  87,  71,\n",
       "         188, 134, 150, 125, 181,  89,  84, 115,  83,  65, 108, 107, 115, 172,\n",
       "          14, 141,  95, 101,  65,  33,  70, 139, 143,  82, 170,  52, 174,  24,\n",
       "          11,  94,  39, 113, 155, 146, 182,  58,  91, 188, 171,  44, 110, 107,\n",
       "           7, 106, 138,  87,  38,   8,  69,  58, 102,  34, 107,  64, 170,  97,\n",
       "         113, 152,  35, 108,  79,  95, 128, 158, 180, 104,  92, 179,  97, 178,\n",
       "          28, 164,  41,  41, 163, 137, 130,  36, 136, 164, 155, 182, 132,  98,\n",
       "         128,  58, 152, 164, 195, 159,  16,  55, 101, 188, 157, 172,  91,  52,\n",
       "         124, 142,  89,  71,  47, 174, 131, 147,  50,  38,  10,  30, 192, 160,\n",
       "           2, 155, 144,  62,  50, 122, 149,  95, 106,  71, 128, 182, 189, 171,\n",
       "         154,  32, 156, 145, 112,  71,  78,  49,  25, 174, 136, 173, 102,  82,\n",
       "          53,  11,  22,   3, 123, 152, 140, 182, 192, 112,  72,  12, 113,  58,\n",
       "          16, 126, 155,  53, 130, 113, 163,  50,  85, 184,  77, 116,  73, 100,\n",
       "         193,  24, 119, 137]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a90fd0c0-a056-4339-9466-18b0bcd2b259",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG16(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGG16, self).__init__()\n",
    "        self.layer1 = BasicBlock(3, 64)\n",
    "        self.layer11 = BasicBlock(64, 64)\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.layer2 = BasicBlock(64, 128)\n",
    "        self.layer22 = BasicBlock(128, 128)\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.layer3 = BasicBlock(128, 256)\n",
    "        self.layer4 = BasicBlock(256, 256)\n",
    "        self.layer41 = BasicBlock(256, 256)\n",
    "        self.maxpool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.layer5 = BasicBlock(256, 512)\n",
    "        self.layer6 = BasicBlock(512, 512)\n",
    "        self.layer61 = BasicBlock(512, 512)\n",
    "        self.maxpool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.layer7 = BasicBlock(512, 512)\n",
    "        self.layer8 = BasicBlock(512, 512)\n",
    "        self.layer81 = BasicBlock(512, 512)\n",
    "        self.maxpool5 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512 * 2 * 2, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4096, 196)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer11(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer22(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.layer41(x)\n",
    "        x = self.maxpool3(x)\n",
    "        x = self.layer5(x)\n",
    "        x = self.layer6(x)\n",
    "        x = self.layer61(x)\n",
    "        x = self.maxpool4(x)\n",
    "        x = self.layer7(x)\n",
    "        x = self.layer8(x)\n",
    "        x = self.layer81(x)\n",
    "        x = self.maxpool5(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a1149acd-2f9c-40ac-9a10-b10287f16f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 - Loss: 5.2812 - Accuracy: 0.0075\n",
      "Validation Acc: 0.0025\n",
      "Epoch 2/5 - Loss: 5.2773 - Accuracy: 0.0098\n",
      "Validation Acc: 0.0025\n",
      "Epoch 3/5 - Loss: 5.2763 - Accuracy: 0.0098\n",
      "Validation Acc: 0.0025\n",
      "Epoch 4/5 - Loss: 5.2754 - Accuracy: 0.0098\n",
      "Validation Acc: 0.0025\n",
      "Epoch 5/5 - Loss: 5.2738 - Accuracy: 0.0098\n",
      "Validation Acc: 0.0025\n"
     ]
    }
   ],
   "source": [
    "model = VGG16().to(device)\n",
    "train_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0cfd7460-c060-4ca6-b562-4809ad0c4b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.0098\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.00980392156862745,\n",
       " tensor([118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118]),\n",
       " tensor([ 28, 172,  14,  69,  88, 142,  47,  29,   7,   0, 123,  77, 193, 126,\n",
       "         179,  32, 114, 125, 122,  15,  46, 185,  34,  46,  17,  44, 116,  94,\n",
       "           5, 122, 169,  45, 186,  95,  56, 189,  65, 146,  72, 157, 117,  69,\n",
       "         101,   7,  95,  70,  77, 125, 123,  80, 171,  91,  42,  36, 190,  85,\n",
       "         109,  81, 159, 178, 103, 105, 195, 132, 117,   5, 111, 118, 103, 149,\n",
       "         113, 145,  61,   6, 140,  19, 146,  36,  22, 165, 192,   9,  39,   1,\n",
       "          45, 138, 186,  64,  78, 189, 139,  33, 139,  33, 134,  20, 177, 192,\n",
       "          47,  51,  35, 133, 119, 124, 179, 117, 142,  93, 123, 120,  73,  40,\n",
       "          59, 153, 191,   8, 147,  59,  99,  45, 101, 133,  67,  77,  55,  73,\n",
       "         152, 126, 117, 192,  10, 167,  66, 176,  58, 115,   5, 106, 108, 179,\n",
       "           8,  94, 116,  21,  78, 105,  96, 124, 167,  87, 151, 166, 156,  47,\n",
       "          18,  89,  69,  72, 143,  16,  45,  92, 190, 145, 165, 187,  93,  92,\n",
       "         121, 133, 131, 168, 112, 103,  64, 122, 165, 104,  69,  89,  20,  85,\n",
       "         114, 175, 123, 193,  45, 152, 107, 136,  41, 145,  85,  66,  25,  79,\n",
       "         185,  93,  92,  58,  88,  56,  53,   1, 186, 195,  75,  45,  88, 185,\n",
       "          57,  47,   5,  90, 150, 102,  39,   8,   4, 117,  52, 119, 124, 128,\n",
       "         177, 193, 185,  73,  64, 130,  86,  55, 139, 188, 144,  85, 160,   4,\n",
       "          59,  98, 169,  46,  58, 144,  91, 163, 114,   7, 146, 150,  96,   9,\n",
       "          96, 152, 165, 185, 183, 143,  15, 131,  20, 195, 124, 168,  49, 146,\n",
       "          17, 100, 194,   5, 160,  15,  51,  37,  97,   7,  22, 165,   5,  85,\n",
       "         181, 118,  81,  37, 113,  94,  43,  73,  37,  16,  85,  75, 195,  66,\n",
       "         117,  58,  97,  97, 136,  66, 159, 187, 165, 137, 132, 177, 119, 194,\n",
       "          50, 120,  16, 140,  77,  31, 180,  13, 141, 180, 186, 129,  64,   3,\n",
       "         186, 118, 145,  16,  66, 157,   7, 137, 170,  46,  63,  68,  15,  36,\n",
       "          18, 113,   5, 188,  65, 118,   9,  21, 166, 154, 172,  50,  76, 184,\n",
       "          96, 154,  40,  71, 110, 120, 172,  86, 167,  91,  31,  22,  71,   5,\n",
       "         112,  71,  12,  39, 180,   4,  29, 190, 125,  55,  49,  73, 104,  60,\n",
       "          15,  57,  28,   6, 137,  30,  38, 120, 102, 166,  73, 121, 147,  11,\n",
       "         154, 161, 148, 140, 168,  29, 127,  52, 138, 113, 120,  91,  36,  96,\n",
       "          92, 129,   4, 155, 136,  84,  48,  76, 182,  68, 182,  46,  27, 123,\n",
       "          48,   2,  43, 118, 118,  62, 180,  31,   6, 164, 126,   2, 109, 132,\n",
       "          62, 127,  92,  57,  76, 104, 117, 146, 175,  67, 162, 112, 164,  79,\n",
       "          79,  41, 131, 176, 112,  60, 160, 161, 103, 127,  38,   2, 140,  42,\n",
       "         126, 162,   6,  59, 181,  40, 173,  82,  28,   9,  15, 151,  61, 121,\n",
       "         150, 119, 177, 114,  11,  38, 156, 107,   1,  60,  27,  23, 129, 127,\n",
       "         148, 188, 117, 138, 105, 120, 180, 125, 132, 174, 129, 152,  39, 118,\n",
       "          48, 127,  43,  62, 152, 125,   3, 109, 121,  37,  28,  63,  17, 143,\n",
       "          97,  56, 172, 111,  14,   3, 165, 165,  22,  95, 111, 114, 139,  26,\n",
       "         116, 109,  96, 107,  13,  30, 130, 146,  20, 117,  28,  95, 193,  39,\n",
       "          27,  66,  14,  89,   2,  57,  74,  91,   0, 170,  35,  62, 174, 104,\n",
       "         136, 186, 129, 128,   1,  68,  95, 161, 107,  63,  11, 190,  73, 129,\n",
       "         176,  50, 111, 131, 192,  27,  31,  88, 118, 105, 190, 194, 133,  26,\n",
       "          83, 155,   1,  88,  77, 110,   4,  61, 142, 115, 190,  53,  53, 183,\n",
       "         151,   9, 129, 114,  42,  28, 137,  27, 180, 186, 131,  46, 192,  15,\n",
       "         144,  76,  38,  84,  17, 182,   8, 124,  43, 162, 179,  77,  31,  40,\n",
       "          65, 172,  59, 107,  68,  47, 193, 146,  34,   5, 164,   2,  87,  71,\n",
       "         188, 134, 150, 125, 181,  89,  84, 115,  83,  65, 108, 107, 115, 172,\n",
       "          14, 141,  95, 101,  65,  33,  70, 139, 143,  82, 170,  52, 174,  24,\n",
       "          11,  94,  39, 113, 155, 146, 182,  58,  91, 188, 171,  44, 110, 107,\n",
       "           7, 106, 138,  87,  38,   8,  69,  58, 102,  34, 107,  64, 170,  97,\n",
       "         113, 152,  35, 108,  79,  95, 128, 158, 180, 104,  92, 179,  97, 178,\n",
       "          28, 164,  41,  41, 163, 137, 130,  36, 136, 164, 155, 182, 132,  98,\n",
       "         128,  58, 152, 164, 195, 159,  16,  55, 101, 188, 157, 172,  91,  52,\n",
       "         124, 142,  89,  71,  47, 174, 131, 147,  50,  38,  10,  30, 192, 160,\n",
       "           2, 155, 144,  62,  50, 122, 149,  95, 106,  71, 128, 182, 189, 171,\n",
       "         154,  32, 156, 145, 112,  71,  78,  49,  25, 174, 136, 173, 102,  82,\n",
       "          53,  11,  22,   3, 123, 152, 140, 182, 192, 112,  72,  12, 113,  58,\n",
       "          16, 126, 155,  53, 130, 113, 163,  50,  85, 184,  77, 116,  73, 100,\n",
       "         193,  24, 119, 137]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "22c92878-2d1d-4c67-9039-95ac13dfbd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG19(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGG19, self).__init__()\n",
    "        self.layer1 = BasicBlock(3, 64)\n",
    "        self.layer11 = BasicBlock(64, 64)\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.layer2 = BasicBlock(64, 128)\n",
    "        self.layer22 = BasicBlock(128, 128)\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.layer3 = BasicBlock(128, 256)\n",
    "        self.layer4 = BasicBlock(256, 256)\n",
    "        self.layer41 = BasicBlock(256, 256)\n",
    "        self.layer42 = BasicBlock(256, 256)\n",
    "        self.maxpool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.layer5 = BasicBlock(256, 512)\n",
    "        self.layer6 = BasicBlock(512, 512)\n",
    "        self.layer61 = BasicBlock(512, 512)\n",
    "        self.layer62 = BasicBlock(512, 512)\n",
    "        self.maxpool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.layer7 = BasicBlock(512, 512)\n",
    "        self.layer8 = BasicBlock(512, 512)\n",
    "        self.layer81 = BasicBlock(512, 512)\n",
    "        self.layer82 = BasicBlock(512, 512)\n",
    "        self.maxpool5 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512 * 2 * 2, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4096, 196)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer11(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer22(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.layer41(x)\n",
    "        x = self.layer42(x)\n",
    "        x = self.maxpool3(x)\n",
    "        x = self.layer5(x)\n",
    "        x = self.layer6(x)\n",
    "        x = self.layer61(x)\n",
    "        x = self.layer62(x)\n",
    "        x = self.maxpool4(x)\n",
    "        x = self.layer7(x)\n",
    "        x = self.layer8(x)\n",
    "        x = self.layer81(x)\n",
    "        x = self.layer82(x)\n",
    "        x = self.maxpool5(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "13ab229c-147b-4273-a5ea-05625dbc228d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 - Loss: 5.2808 - Accuracy: 0.0053\n",
      "Validation Acc: 0.0025\n",
      "Epoch 2/5 - Loss: 5.2774 - Accuracy: 0.0098\n",
      "Validation Acc: 0.0025\n",
      "Epoch 3/5 - Loss: 5.2764 - Accuracy: 0.0098\n",
      "Validation Acc: 0.0025\n",
      "Epoch 4/5 - Loss: 5.2754 - Accuracy: 0.0098\n",
      "Validation Acc: 0.0025\n",
      "Epoch 5/5 - Loss: 5.2745 - Accuracy: 0.0098\n",
      "Validation Acc: 0.0025\n"
     ]
    }
   ],
   "source": [
    "model = VGG19().to(device)\n",
    "train_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "070d266f-a1b3-480e-8767-9fe09781bc1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.0098\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.00980392156862745,\n",
       " tensor([118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
       "         118, 118, 118, 118]),\n",
       " tensor([ 28, 172,  14,  69,  88, 142,  47,  29,   7,   0, 123,  77, 193, 126,\n",
       "         179,  32, 114, 125, 122,  15,  46, 185,  34,  46,  17,  44, 116,  94,\n",
       "           5, 122, 169,  45, 186,  95,  56, 189,  65, 146,  72, 157, 117,  69,\n",
       "         101,   7,  95,  70,  77, 125, 123,  80, 171,  91,  42,  36, 190,  85,\n",
       "         109,  81, 159, 178, 103, 105, 195, 132, 117,   5, 111, 118, 103, 149,\n",
       "         113, 145,  61,   6, 140,  19, 146,  36,  22, 165, 192,   9,  39,   1,\n",
       "          45, 138, 186,  64,  78, 189, 139,  33, 139,  33, 134,  20, 177, 192,\n",
       "          47,  51,  35, 133, 119, 124, 179, 117, 142,  93, 123, 120,  73,  40,\n",
       "          59, 153, 191,   8, 147,  59,  99,  45, 101, 133,  67,  77,  55,  73,\n",
       "         152, 126, 117, 192,  10, 167,  66, 176,  58, 115,   5, 106, 108, 179,\n",
       "           8,  94, 116,  21,  78, 105,  96, 124, 167,  87, 151, 166, 156,  47,\n",
       "          18,  89,  69,  72, 143,  16,  45,  92, 190, 145, 165, 187,  93,  92,\n",
       "         121, 133, 131, 168, 112, 103,  64, 122, 165, 104,  69,  89,  20,  85,\n",
       "         114, 175, 123, 193,  45, 152, 107, 136,  41, 145,  85,  66,  25,  79,\n",
       "         185,  93,  92,  58,  88,  56,  53,   1, 186, 195,  75,  45,  88, 185,\n",
       "          57,  47,   5,  90, 150, 102,  39,   8,   4, 117,  52, 119, 124, 128,\n",
       "         177, 193, 185,  73,  64, 130,  86,  55, 139, 188, 144,  85, 160,   4,\n",
       "          59,  98, 169,  46,  58, 144,  91, 163, 114,   7, 146, 150,  96,   9,\n",
       "          96, 152, 165, 185, 183, 143,  15, 131,  20, 195, 124, 168,  49, 146,\n",
       "          17, 100, 194,   5, 160,  15,  51,  37,  97,   7,  22, 165,   5,  85,\n",
       "         181, 118,  81,  37, 113,  94,  43,  73,  37,  16,  85,  75, 195,  66,\n",
       "         117,  58,  97,  97, 136,  66, 159, 187, 165, 137, 132, 177, 119, 194,\n",
       "          50, 120,  16, 140,  77,  31, 180,  13, 141, 180, 186, 129,  64,   3,\n",
       "         186, 118, 145,  16,  66, 157,   7, 137, 170,  46,  63,  68,  15,  36,\n",
       "          18, 113,   5, 188,  65, 118,   9,  21, 166, 154, 172,  50,  76, 184,\n",
       "          96, 154,  40,  71, 110, 120, 172,  86, 167,  91,  31,  22,  71,   5,\n",
       "         112,  71,  12,  39, 180,   4,  29, 190, 125,  55,  49,  73, 104,  60,\n",
       "          15,  57,  28,   6, 137,  30,  38, 120, 102, 166,  73, 121, 147,  11,\n",
       "         154, 161, 148, 140, 168,  29, 127,  52, 138, 113, 120,  91,  36,  96,\n",
       "          92, 129,   4, 155, 136,  84,  48,  76, 182,  68, 182,  46,  27, 123,\n",
       "          48,   2,  43, 118, 118,  62, 180,  31,   6, 164, 126,   2, 109, 132,\n",
       "          62, 127,  92,  57,  76, 104, 117, 146, 175,  67, 162, 112, 164,  79,\n",
       "          79,  41, 131, 176, 112,  60, 160, 161, 103, 127,  38,   2, 140,  42,\n",
       "         126, 162,   6,  59, 181,  40, 173,  82,  28,   9,  15, 151,  61, 121,\n",
       "         150, 119, 177, 114,  11,  38, 156, 107,   1,  60,  27,  23, 129, 127,\n",
       "         148, 188, 117, 138, 105, 120, 180, 125, 132, 174, 129, 152,  39, 118,\n",
       "          48, 127,  43,  62, 152, 125,   3, 109, 121,  37,  28,  63,  17, 143,\n",
       "          97,  56, 172, 111,  14,   3, 165, 165,  22,  95, 111, 114, 139,  26,\n",
       "         116, 109,  96, 107,  13,  30, 130, 146,  20, 117,  28,  95, 193,  39,\n",
       "          27,  66,  14,  89,   2,  57,  74,  91,   0, 170,  35,  62, 174, 104,\n",
       "         136, 186, 129, 128,   1,  68,  95, 161, 107,  63,  11, 190,  73, 129,\n",
       "         176,  50, 111, 131, 192,  27,  31,  88, 118, 105, 190, 194, 133,  26,\n",
       "          83, 155,   1,  88,  77, 110,   4,  61, 142, 115, 190,  53,  53, 183,\n",
       "         151,   9, 129, 114,  42,  28, 137,  27, 180, 186, 131,  46, 192,  15,\n",
       "         144,  76,  38,  84,  17, 182,   8, 124,  43, 162, 179,  77,  31,  40,\n",
       "          65, 172,  59, 107,  68,  47, 193, 146,  34,   5, 164,   2,  87,  71,\n",
       "         188, 134, 150, 125, 181,  89,  84, 115,  83,  65, 108, 107, 115, 172,\n",
       "          14, 141,  95, 101,  65,  33,  70, 139, 143,  82, 170,  52, 174,  24,\n",
       "          11,  94,  39, 113, 155, 146, 182,  58,  91, 188, 171,  44, 110, 107,\n",
       "           7, 106, 138,  87,  38,   8,  69,  58, 102,  34, 107,  64, 170,  97,\n",
       "         113, 152,  35, 108,  79,  95, 128, 158, 180, 104,  92, 179,  97, 178,\n",
       "          28, 164,  41,  41, 163, 137, 130,  36, 136, 164, 155, 182, 132,  98,\n",
       "         128,  58, 152, 164, 195, 159,  16,  55, 101, 188, 157, 172,  91,  52,\n",
       "         124, 142,  89,  71,  47, 174, 131, 147,  50,  38,  10,  30, 192, 160,\n",
       "           2, 155, 144,  62,  50, 122, 149,  95, 106,  71, 128, 182, 189, 171,\n",
       "         154,  32, 156, 145, 112,  71,  78,  49,  25, 174, 136, 173, 102,  82,\n",
       "          53,  11,  22,   3, 123, 152, 140, 182, 192, 112,  72,  12, 113,  58,\n",
       "          16, 126, 155,  53, 130, 113, 163,  50,  85, 184,  77, 116,  73, 100,\n",
       "         193,  24, 119, 137]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b87cad-290d-49f6-9b0e-ec99be48c2c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
